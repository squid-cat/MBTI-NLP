{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\squid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data\n",
    "datas = pd.read_csv('./data/csv/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove text noise\n",
    "def clear_text(data):\n",
    "    data_length=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    cleaned_text=[]\n",
    "    for sentence in tqdm(data.posts):\n",
    "      sentence=sentence.lower()\n",
    "        \n",
    "      #  removing links from text data\n",
    "      sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n",
    "    \n",
    "      # removing other symbols\n",
    "      sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "           \n",
    "      data_length.append(len(sentence.split()))\n",
    "      cleaned_text.append(sentence)\n",
    "    \n",
    "    return cleaned_text,data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6940/6940 [00:02<00:00, 2515.25it/s]\n",
      "100%|██████████| 1735/1735 [00:00<00:00, 2298.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data=train_test_split(datas,test_size=0.2,random_state=42,stratify=datas.type)\n",
    "\n",
    "train_data.posts,train_length=clear_text(train_data)\n",
    "test_data.posts,test_length=clear_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "vectorizer.fit(train_data.posts)\n",
    "\n",
    "train_post=vectorizer.transform(train_data.posts).toarray()\n",
    "test_post=vectorizer.transform(test_data.posts).toarray()\n",
    "\n",
    "target_encoder=LabelEncoder()\n",
    "train_target=target_encoder.fit_transform(train_data.type)\n",
    "test_target=target_encoder.fit_transform(test_data.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneVsRestClassifier\n",
    "estimator = SVC()\n",
    "model_one_vs_rest=OneVsRestClassifier(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one_vs_rest.fit(train_post, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.69      0.24      0.35        38\n",
      "        ENFP       0.73      0.59      0.65       135\n",
      "        ENTJ       0.65      0.37      0.47        46\n",
      "        ENTP       0.60      0.56      0.58       137\n",
      "        ESFJ       1.00      0.33      0.50         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       1.00      0.12      0.22         8\n",
      "        ESTP       0.60      0.33      0.43        18\n",
      "        INFJ       0.70      0.72      0.71       294\n",
      "        INFP       0.64      0.86      0.73       366\n",
      "        INTJ       0.64      0.65      0.64       218\n",
      "        INTP       0.70      0.82      0.76       261\n",
      "        ISFJ       0.64      0.42      0.51        33\n",
      "        ISFP       0.81      0.41      0.54        54\n",
      "        ISTJ       0.73      0.27      0.39        41\n",
      "        ISTP       0.69      0.63      0.66        67\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.68      0.46      0.51      1735\n",
      "weighted avg       0.67      0.67      0.66      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('test classification report \\n ',classification_report(test_target,model_one_vs_rest.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359885482496 2359902745408\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "# 学習モデルをコピー\n",
    "model_one_vs_rest_tuning = copy(model_one_vs_rest)\n",
    "print(id(model_one_vs_rest), id(model_one_vs_rest_tuning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ファインチューニング\n",
    "tuning_datas = pd.DataFrame(data=[[\"ENFP\", open(\"./data/text/lookback/momoka_en.txt\", \"r\", encoding='UTF-8').read()],\n",
    "                [\"ESFJ\", open(\"./data/text/lookback/issei_en.txt\", \"r\", encoding='UTF-8').read()],\n",
    "                [\"ESFP\", open(\"./data/text/lookback/kai_en.txt\", \"r\", encoding='UTF-8').read()],\n",
    "                [\"ENFP\", open(\"./data/text/lookback/keito_en.txt\", \"r\", encoding='UTF-8').read()],\n",
    "                [\"ISFP\", open(\"./data/text/lookback/katuki_en.txt\", \"r\", encoding='UTF-8').read()]], columns=[\"type\", \"posts\"])\n",
    "tuning_posts = vectorizer.transform(tuning_datas.posts).toarray()\n",
    "tuning_target = target_encoder.transform(tuning_datas.type)\n",
    "model_one_vs_rest_tuning.fit(tuning_posts, tuning_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMBTI(words):\n",
    "  words_vec = vectorizer.transform([words]).toarray()\n",
    "  print(\"チューニングなし: \", model_one_vs_rest.predict(words_vec), target_encoder.inverse_transform(model_one_vs_rest.predict(words_vec))[0])\n",
    "  print(\"チューニングあり: \", model_one_vs_rest_tuning.predict(words_vec), target_encoder.inverse_transform(model_one_vs_rest_tuning.predict(words_vec))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session10 発話データ\n",
      "チューニングなし:  [11] INTP\n",
      "チューニングあり:  [1] ENFP\n",
      "session1~10 振り返りシート\n",
      "チューニングなし:  [10] INTJ\n",
      "チューニングあり:  [1] ENFP\n"
     ]
    }
   ],
   "source": [
    "# momoka ENFP\n",
    "# session10 5min\n",
    "print(\"session10 発話データ\")\n",
    "getMBTI(\"Certainly, with today's technology, I think you don't have to go and see them anymore to see them in a great way, but then I thought, why did you bring them here at the zoo? But then, why did you come to the zoo? Plus, the zoo fees are fairly inexpensive, but it would probably cost a fair amount of money to go and see the animals in person, or to use the equipment. I thought that the zoo was created to make it easy to see the animals. What do you think? I don't know. I don't know. Yes, I think that the loss of the wild function would take away the good parts of the animal. Nowadays, people talk about the importance of individuality, so I wonder if that is part of it.\")\n",
    "print(\"session1~10 振り返りシート\")\n",
    "getMBTI(open(\"./data/text/lookback/momoka_en.txt\", \"r\", encoding='UTF-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session10 発話データ\n",
      "チューニングなし:  [11] INTP\n",
      "チューニングあり:  [1] ENFP\n",
      "session1~10 振り返りシート\n",
      "チューニングなし:  [10] INTJ\n",
      "チューニングあり:  [4] ESFJ\n"
     ]
    }
   ],
   "source": [
    "# issei ESFJ session10\n",
    "print(\"session10 発話データ\")\n",
    "getMBTI(\"Yes, for three weeks, but the reason for this is that I think zoos also have the role of protecting animals, and animals that cannot live on their own due to the harsh environment, global warming, deforestation, etc., have a difficult time living in zoos. I wondered which of the two was more necessary. I think it is true that humans are responsible for the destruction of the environment, but I also believe that it is because of the actions of the next generation of humans that we are able to protect the environment.\")\n",
    "print(\"session1~10 振り返りシート\")\n",
    "getMBTI(open(\"./data/text/lookback/issei_en.txt\", \"r\", encoding='UTF-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session10 発話データ\n",
      "チューニングなし:  [9] INFP\n",
      "チューニングあり:  [1] ENFP\n",
      "session1~10 振り返りシート\n",
      "チューニングなし:  [10] INTJ\n",
      "チューニングあり:  [5] ESFP\n"
     ]
    }
   ],
   "source": [
    "# kai ESFP session10\n",
    "print(\"session10 発話データ\")\n",
    "getMBTI(\"Yes, I am. I would like to hear the opinions of those who are in favor of the zoo first. I see. Thank you very much. Do you have any questions for the main section? I see. Thank you very much. I think that one of the opinions of the proponents is the protection of animals, and the other is that people will be interested in animals when they see them. Then I would like to move on to 3, the opponents' opinions. I see. Thank you very much. I would like to speak next, but I think my opinion would be a bit like a rebuttal to your opinion, but nowadays, various technologies have developed. In the past, there was little such technology, and many people had no choice but to go and see the animals in person, or there was nothing to see even if they took pictures of the animals. I think the value of zoos was high as a place to learn about things, but nowadays there are a lot of resources available, and I think it's fine not to go to the trouble of putting animals in a zoo and observing them, but it's easy to do so. I think it is better to casually take animals that are living in the wild and view them in that way than to put them in a world that is like a prison, and I think it is better for me to study them. So, you know, one thing I disagree with is your reaction. I also responded to Momoka's opinion, saying that there must be some way to learn about animals or to get people interested in them, even if it is not in an individual zoo. I would like to ask you, Mr. Ishii, if you have any objections or even sympathies for Mr. Keita's opinion, that you heard earlier, that would be totally fine. Do you have any?\")\n",
    "print(\"session1~10 振り返りシート\")\n",
    "getMBTI(open(\"./data/text/lookback/kai_en.txt\", \"r\", encoding='UTF-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session10 発話データ\n",
      "チューニングなし:  [11] INTP\n",
      "チューニングあり:  [1] ENFP\n",
      "session1~10 振り返りシート\n",
      "チューニングなし:  [10] INTJ\n",
      "チューニングあり:  [1] ENFP\n"
     ]
    }
   ],
   "source": [
    "# keito ENFP session10\n",
    "print(\"session10 発話データ\")\n",
    "getMBTI(\"The opponents' point of view is protection, but it was humans who created the conditions that made it necessary to reinforce the situation in the first place, and it was not humans who experienced all the environmental destruction and global warming. For example, in the case of global warming, it was exhaust emissions, deforestation, and wages for the land needed to build towns and cities, but the animals could no longer live there, so we said we would build zoos and protect them. But only a small percentage of the animals can be protected, and all the animals living in the logged area cannot be sent to the zoo, so they are driven away. So, I think that what the zoo has created is only English for humans, and that's why I have this opinion. It's a different opposing opinion. Yeah.\")\n",
    "print(\"session1~10 振り返りシート\")\n",
    "getMBTI(open(\"./data/text/lookback/keito_en.txt\", \"r\", encoding='UTF-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session1~10 振り返りシート\n",
      "チューニングなし:  [10] INTJ\n",
      "チューニングあり:  [13] ISFP\n"
     ]
    }
   ],
   "source": [
    "# katuki ISFP\n",
    "print(\"session1~10 振り返りシート\")\n",
    "getMBTI(open(\"./data/text/lookback/katuki_en.txt\", \"r\", encoding='UTF-8').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a85d2ef23d6583666fa71d3e08c04afc19f58e3c237388c1b61eada76bc58ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
